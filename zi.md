想要和杨老师交流的
可以在评论区或者弹幕当中提出字数限制
没有关系
可以分多条提出
我们的工作人员将汇总这些问题
并在讲座的最后呢
请杨老师选择回答
所以接下来请小伙伴们在公屏上打出欢迎二字
有请杨斌教授
好杨老师好嘞
谢谢关老师
谢谢关老师的精彩介绍
我想你把这个我今天要讲的这个这个topic的
这个这个背景和为什么要做这件事
您说的说的非常透彻
我就可以直入直入主题了
哦我看一下
诶郭老师能看到我这个share这个屏幕吗
没问题啊
没问题好
那那我就开始了
好好
今天非常高兴
非常高兴能有这个机会跟大家能够分享一下
我们最近在呃时间序列分析
尤其是自动化的
时间序列分析的一些最新的进展啊
特别感谢关老师能够呃呃给我这次宝贵的机会
能跟大家做这次这次分享啊
这个是我我主要是和在我去年回国之前啊
主要的工作还是在在丹麦完成了呃
主要是关于时间序列分析
就是说怎么样啊
通过一些自动化的方法
而不是用啊case by case
和这个人工手动设计的方法去呃
解决这个比较比较呃challenge这个问题
首先呢呃我先讲一下
这个我们关注的这个时间序列啊
预测啊
它是一种特殊的一个时间序列分析
时间序列分析可能包括了啊
包括预测呀
异常检测和分类
那我今天主要讲的是这个其中一类
就是时间序列的预测啊
刚才郭老师也提到了
就是现在在呃时空啊相关的一些领域呢
很多时间序列会出现
而且呢这些时间序列呢是跟空间相关的
这些时间序列可能大量存在之后
他们不同的时间序列之间呢
可能是有一个相互关联的关系的
比如说呃这是呃一个地图
我们可能会用一个道路网络
去把这个地图建模出来
然后呢在每一条道路上或者每一条边上
我们可能都会部署了大量的传感器
这样的话
比如说呃这两条路上布置的传感器
捕捉到的两条时间序列呢
它那么可能之间就存在着比较啊
比较各种各样的相关的相关的关系吧
就我们需要把它的相关关系
和他的随着时间的变化都要都要建模出来
然后呢预测呢就非常简单了
这个意思就是说我我通过回看一个历史窗口
然后我希望能够得到啊未来是什么样子的啊
为什么说这个时间序列预测它非常重要呢
因为时间序列预测能啊
不仅是呃做时间序列预测这一件事
他其实为呃很多其他的分析也奠定一个基础
比如说啊我们如果要做异常检测的话啊
一个通常的做法就是
我首先去对未来进行一个预测啊
如果预测的值和你最后真实的值
差距比较大的话
我就可以把这个当做是一个异常啊
把它检测出来
所以说呢异常检测啊
所以说这个时间序列
时间序列的预测呢是一个比较比较基础的一个
时间序列分析的功能
所以呢
我们今天主要针对的就是时间序列的预测
然后呢基于此呢
我们就对它一个进行一个
先对它进行一个形式化的定义
形式化的定义呢就是我我有一大堆啊
互相关联的时间序列数据
时间序列数据呢就表示成了这个一个三维的
一个一个tensor
那个n呢就表示的是我有多少个传感器
每个传感器呢都产生了一条时间序列
这样的话我就有n条时间序列
然后每一条时间序列呢可能是带有c维的呃
这个呃属性
比如说我在一个位置部署的传感器呢
它可能去啊捕捉到啊这个啊车流量
还有行驶速度
这样的话c就代表的是等于二
然后t呢就是我总共有多少个时间时间戳
然后呢
预测呢就是在根据我历史窗口回看h个呃
时间戳
然后呢我希望去预测下f个时间戳
这就是一个呃一个非常啊
非常直观的一个预测的定义
然后呢我接下来想讲一下
就是啊为什么我们会做这个自动化这件事啊
这件事呢其实啊是基于我们对一个现有的呃
研究的一个分析
我们现有的现有的研究分析的情况是这样的
就是呃最近呢由于这个深度学习的呃
非常的非常的流行
然后呢
呃现在大部分c t s就是相关时间序列预测的
这个这个方向的一些表现
最好的这些方法
其实都是由啊这个深度学习的方法来来统治了
他们已经能够比较轻松的打败啊
传统的基于统计学的一些一些方法
然后这些深度学习的方法呢一般都会啊
包括两个两个模块吧
就第一个模块呢是呃
如何去对这个时间的相关性
或者说时间的动态性去建模
这里面比较常见的方法就有
比如说呃rn呢啊t cn呢还有这个transformer
然后另外一个模块呢
就是怎么样去对这个不同的时间序列
或者说不同的这些呃
实体之间的相关性进行一个建模
这里面常用的两种大大类的方法呢
就两大类方法的一个就是图卷积
另外一个就是还是attention
比如说transformerly
然后呢现在的不同的深度学习的方法
怎么去做时间序列预测呢
就是把这两大类的呃
这两个大模块里边分别找一些
然后进行一个拼凑啊
或者说一个组合
比如说这个dc r n呢就是一个rn家族的
加上一个graph com bushs d g c n呢就是t cn家族
然后再加一个gcn
这样的话就能够呃
既对这个时间的相关性进行一个建模
并且呢对这个不同时间序列之间的相
关性的进行建模
这样的话就能够比较好的去达到一个
相关时间序列的预测的这个效果
然后呢我们基于此研究
这个研究现状的一个总结
我们就想哎我们如果要做研究的话
我们怎么样去推进这个sa的好
继续往前走呢
当然最简单的一个一个路线
可能就是我我们就再提一个这种所谓的end to end
的一个一个预测的模型对吧
就是我们可以呃再去搞一个没有人
以前没有人做过这种一种组合啊
或者是一个复杂的组合
比如说有三明治的这种架构
比如说上面一层啊
呃时间的中间一层是相关性的
底下再可以再加一个时间的
然后各种各种各样的这种不同的组合
再去一个n tn的一个模型
但这种模型我们觉得可能就是呃
这个双人性可能也也也相对比较差
或者说他的啊这个就有点属于这种拍脑门想吧
就说我我随便再怎么样找一个奇奇怪怪的组合
诶
这个可能没有人没有人提出过
然后这个可能确实也是note上是有的
但是为什么这么做
可能也去很难的去一个用一个系统化的方法
去来去来justify
所以我们觉得这种方式可能并不是一个
特别好的一个
推动这个这个sota往前走的一个方式
然后呢我们就想到另外两种方式
这两种方式呢就是带有一定的自动
自动化设计的这个这个理念在里面
第一个呢就是说我能不能呃
因为现在已经有很多这样的预测模型了
那我能不能用一个什么样的自动化的方式
我能够把现有的模型的这个这个效果
能够能够自动的往上再提升一些
就怎么样去自动的去提升现有模型的
一个一个一个效果
第二个呢就是呃更往前走一步
我我已经知道了
这个啊有什么很有很多这些模型
这些模型的基础模块呢
其实我也了解了
那我们能不能自动的去啊去啊
让这个算法自动的去搜索出来
或者自动去设计一个一个新的一个模型
这个新的模型呢可能比现有的模型
人们手动手动设计的这些模型的表现都要好
这个就是我今天想要讲的两两个
两个技术路线吧
就是一个是呃
怎么样用自动方法去提升现有模型的效果
另外一个就是说怎么样通过已有的呃
一些基础的模块去设计出来一个全新的保险
那首先呢我先讲一下第一个技术路线
怎么样能够自动的去呃
提高现有模型的一个一个效果
然后我们提出了一个叫做enhancement啊
这个enhancement呢啊它的大体的思想是这样的
就是根据我们之前的分析啊
现有的方法呢主要分为两个大模块
第一个模块呢就是不同的方法去对呃
时间的相关性进行建模
然后呢
第二个是对他们不同时间序列之间的相关性
进行一个建模
然后我们就提出我们能不能用两个plug in
就是所谓的插入网络
一个小的插入网络
你要分别的对这两个模块进行提升
对就是我我通过这个呃temporal plugin
去
怎么样去更好的把这个
让这些已有的模型能够更好的去捕捉
他们的temporal dynamics
然后我们再用一个correlation plug in
然后我们希望他能够对这个entity
correlation能够进行一个更好的一个建模
这样的话我们通过这两个
不管你这个原始的这个呃forecasting
就是预测模型
它用的是什么样一个组合
但是我们通过这两个plugin
都能够对它进行一个效果的提升
这样的话
我们就这就是我们的一个基本的大的思想
就是我们不去再提一个新的end
to end的一个模型了
而是我们提一个呃plugin network
这个plugin network它可以啊呃非常方便的啊
嵌入到已有的这个这个预测模型里面去
这样呢使得这个预测
已有的预测模型的效果能够有一定的提高
那现在问题就是
那我们怎么样去啊
对这个对这个业务模型进行一个增强了
所谓的in enhance就怎么去做这件事呢
然后我们就看了一下呃
相关的一些数据
从数据出发吧
我们的我们的方法其实是data driven的
所以data driven就是基于数据的方法
那我们就先看看数据
然后呢我们第一个发现了一个特征呢
就是在不同不同的时间序列
或者说不同的这个传感器
采出来的这些时间序列
它们经常是有比较啊独特的特征的
比如说这里可以看到一
一和二他俩的这个时间序列也是比较像的
然后三和四呢他俩是比较像的
但是一和二和三和四相比呢
他们的这个时间上的这个变化的规律
还是有比较大的区别的
那但是现在已有的模型呢
现在现在已有的这个预测模型
他们都面临着一个同样的问题
就是说他们会用同样的这个模型参数
这种同样的模型参数给所有的这个呃
所有的这些实体
或者说所有的时间序列
都是用的是同一套这个模型参数
那这样的话可能就没法达到
这个能够捕捉到不同的这个实体
它有不同的这个比较特殊的这个呃空间关系
这个这个点
所以这个点是可以我们去进行一个呃
增强了一个一个一个点
然后第二个点呢就是它们的之间的相关性
然后呢就是我们通过一些实时数据的
真实数据的分析吧
我们就发现这个相关性可能是随着时间变化的
但是呢现有的模现有的这个forecasting模型呢
大部分呢它其实都是用的是
基于呃这个传感器的部署的位置
然后通过他们的背部署的位置
然后计算它们的距离
然后通过距离来呃
来对他们的相关性进行一个一个呃一个建模
就比如说他们离得越近的话
他们的相关就应该越大
离得越远的话
它们相关性就应该越小
但是呢这种基于距离的建模方式呢
它的这个是一个静态的
一个一个呃相关性的一个捕捉
它并不能捕捉这个随着时间变化而产生的
相关性的变化
比如说这里面一个例子
就是看到八点和九点钟的话
他们之间的相关性是其实是随着时间变化的
那这个点呢也是我们在这个银行net里面
想通过一个小的一个plug in network
去去对它做一个提升的
那接下来我就对这两个点啊
就这就是我们提出的这个enhance net
它的两个点
它的第一个点怎么样去提升这个tempore
temporal dynamics建模呢
就是通过对不同的传感器
或者说不同的时间序列
我给它生成一组啊特殊的呃模型参数
然后这个和对他这个相关性进行建模
就是通过一个方法能够对它的啊
随着时间变化的这个相关性
能够一个更好的建模
这就是我们的一个大体的思想
接下来我看我们来看一下啊
我们是怎么具体啊具体做这件事的呃
首先呢我这里边就呃
首先提到的就是两个基础的模型
一个是嗯rn
一个就是呃
一个就是这个啊t cn的它的一些基本的情况
就是我们这里可以看到呢
就是刚才我说的什么意思呢
就是不同的时间序列
它用的都是同一组啊
这个模型参数
这里面我们可以看到
这个上角标的i其实代表的是第i条时间序列
然后呢你可以看到
虽然我们这个i可能是不一样的
比如说我们有十条是时间序列的话
我们i就从一到十
但是呢我前面用的w r幼儿这两个矩阵
它总是用同样的w r和ur
也就是说
我虽然我的第一条时间序列和第三条时间序列
可能是呃完全具有完全不一样的
这个时间的规律
但是呢w r和ur代表这些参数呢是一致的
对吧
同样的道理在这个t cn这边的话
但是呢我前面的这个filter就是它这个convolution
这个卷积核
它这个f呢也是同样的
它并没有随着a的变化而而改而发生改变
这就是它的一个一个呃潜在的一个一个limitation
或者它的一个限制
然后我们通过呢希望通过某种方式
能够对不同的时间序列或者说不同传感器呃
到来的数据呢能够进行一个特殊的建模
但是最简单的一个方法呢
我们呃就是也可以对每一个时间序列
也去给他学一个跟这个时间序列相关的
一个一个一个参数
比如说我们这可以简单的去嗯对答进行
而不是用一个同一个w和u
而是用一个w i的一个一个set和ui的一个set
但是这个方法呢
当你这个时间序列的个数比较多的时候
比如说n非常大
比如说一上千或者上万的时候
那我们要学习的这个这个呃w和u的
这个可学习的这个这个参数呢
就会随着这个n的增加而大幅的增加
这样的话对这个不管是从效率来说
还是从呃
他可能因为由于这个模型的参数
可学习的参数越多
导致了可能过过拟合的情况的发生呢
就会越来越越明显
所以我们不希望通过一个简单的这种方式呃
来来增
简单的通过这个增加可学习的这个参数的个数
来来解决这个问题
那我们就提出了一个呃基于生成网络
进行了一个一个呃一个方式
这里面的一个主要的思想就是呃
我给每一个传感器或者说每一条时间序列
我去给他一个可以训练的一个memory
就是一个一个一个小的标量的一个一个数据
这个标小的标量的memory呢
就是代表了这个跟这个是呃
跟这个传感器
或者跟这条时间序列相关的一些呃
隐藏的一些特征
那这个特征呢是可以可以经过训练去调整的
然后通过这个这个可学习的呃
并且是每一个传感器都有呃
呃都有一个独特的这一份传感器呢
我通过一个简单的生成网络
就比如说是一个简单的呃fully connected neural network
然后我去生成它相对应的一个呃
一个模型的参数
就是通过一个小的m i
然后生成w i和ui
你要这样的话
虽然我可能有很多个时间序列
但是呢我我只要给每一个时间序列去去保
保留一个比较小的这个mi就可以了
然后通过这个生成网络呢
我可以生成对这个呃时间序列相关的
这个相关呃
对应的这个模型参数
比如说对rn里面的话
就是这里面的weight weight的参数
如果是t cn的话
就是它的这个future
然后这个这个生产网络呢其实是model agnostic
就是说它和你的具体使用的呃
预测模型是无关的
就不管你是用r n
我可以生成rn相关的参数
你给我用t cn
我可以生成t cn相关的参数
如果比如说你可以可以用呃transformer
那么transformer的话
我也可以可以生成
跟这个呃具体的时间序列相关的啊
projection metrics
所以说这个网络呢
这个d f g n
这个网络是一个跟你的具体的预测模型的
呃
这个采用哪个模型是不相关的啊
并且呢这个小的网络呢啊可以啊
可以有效的抑制过拟合
因为所有的啊这些不同的时间序列的参数呢
都是通过这同样一个比较小的网络去生成的
这样的话就可以有效的进行一个一个政策化
唉
这就是我们如何通过这个
通过一个给每一个传感器啊
维持一个小的memory
然后能够生成跟他呃特性相关的一些构参数
你要通过通过这个网络呢
我们就可以把这个网络嵌入到
不管是嵌入到r n还是t cn里面去
r n的话就是通过这样一个模式
我我首先根据第几条时间序列
比如说第二条时间序列
那我就把它对应的这个memory调出来
然后通过这个小的生成网络
生成它跟它相关的w i和ui
然后我就用这个w i和ui
去进行这个gr u的操作
那同样的在tcn这边啊
我我有三个生成网络
对应它不同
每一层我都用一个不同的生成网络
当你第二条时间去掉来了之后呢
我就用它对应的这个memory
然后呢我通过这个不同的层的这个生产广告呢
生成对应于这个时间序列这一层的
具体的这个filter
然后用这个filter呢继续进行这个t cn的操作
这样的话就解决了啊
不同的时间序列
我可以用一个呃
一个不同的一组呃参数来对它进行建模
这样啊来达到更好的让它捕捉到时间的相关性
那接下来呢啊我讲一下就是呃第二个增强的点
第二个增强的点就是怎么样去呃让它捕捉到啊
随着时间变化的相关性
这里面呢我们也是通过一个呃一个生成网络啊
就是说这个生成网络叫做啊动态连接矩阵
生成网络
那它是由三部分组成的啊
这三部分组成分别是什么意思呢
啊
第一个a其实呢就是传统的这个呃
graph neural network
就是图选及网络用到的这个additional patrix
它就是基于distance
就是距离越近呢
它们的相关性就越大
距离越远呢
他们的相关性就呃就越小啊
第二个b呢其实是一个可学习的连接矩阵
这个可学习的理解矩阵的意思呢
就是呃这其实在之前的工作中已经有人用到了
我们就把它保存下来
他的他的这个intuition
就是说呃它虽然也是静态的
但是它这个静态的相关性
可能不仅仅是跟distance相关的
就不不仅仅是嗯由于它的距离的原因导致的
可能可能还是一些可能
他潜在的一些其他的一些特征来导致的
比如说它周边有没有相同的b o y啊
或者说它周边是不是都是同一个同一个类型的
呃
同一个类型的这个啊环境啊
这些可能是也会导致他们之间的这个呃
空间上的相关性
但是呢它是静态的
因为比如说你周边都是相同的
p o i它是不会随着时间变化的
或者说它随着时间变化的
这个会速速率会比较慢
然后c矩阵呢是我们这里面主要啊
创新的一个一个点
就是它通过呃当前的窗口的数据
xt xt就是从当前时刻t回看一个h的窗口
然后我通过这个xt数据
你要不同的t时刻的话
我对xt其实是不同的
然后我通过这个xt呢
你要通过一些呃这些变化
然后我生成一个新的一个矩阵
这个c矩阵
这个c矩阵呢就代表了一个呃当前时间呃
当前的时间戳下
然后不同的时间序列之间的相关性
你看我最后呢把它们进行一个加权和
就最后得到这个a一撇
这个矩阵呢就是一个能够捕捉到动态相关性的
一个一个临界矩阵
然后呢我用这个a撇去呃
进行相关的啊凸显机操作
这样的话就可以捕捉到这个
随着时间变化的一个相关性
然后这里面是呃讲了一些他的一个技术细节
那就是b b矩阵
就是刚才我们提到的是
它虽然还是静态的
但是它是可学习的一个一个矩阵
那这里面呢我们就是用两个可学习的参数
b一和b2 
然后对它进行一个内积
然后再进行一个review之后在一个soft max
然后得到了一个呃n乘n的一个一个矩阵
n代表的是时间序列的个数
然后这里面c呢啊其实我们是这么做的
就是我们把当前这个时间时间窗内
比如说这回看12个时间窗
然后呢这个第i个呃时间序列的数据拿过来
然后把dj的时间序列的数据也拿过来
然后我们用分别用sa和fi
这两个其实就是一个简单的啊线性变换
然后线性变换之后呢
我就去对它进行一个一个内机的操作
然后呢最后呢进行一个对它进行一个归一化
其实就是啊做了一个相当于一个呃加权盒的
一个一个一个操作
然后这样的话就通过呃
当前的数据来捕捉到一些相关性
然后呢我把a b c加到一起
然后生成一个随着士兵可以变化的
相关性的矩阵
这样的话能够让呃这个呃graph convolution
能够更好的保持到啊
随着时间变化产生的这个不同的相关性
基于此呢
这就是我们两个plugin
这个小网络的一个设计的理念
然后呢
接下来我们做了相关的实验
去证明一下我们这两个小的plugin network
它真的啊确实是有效的
我们考虑到不同的数据集啊
前两个是交通数据集呃
他们通过分别都是加州的啊
不同的区域啊
第一个是有182个传感器
第二个是207个传感器
然后第三个数据集是一个关于气象的
这个时间序列数据
然后每一个每一个呃
它有一个就相当于36个气象站
然后每个气象站其实捕捉到了六个啊
属性关于这个呃温度
然后湿度还有气压等等
然后我们分别做了70 十和20的这个呃
training和validation和test的一个操作
然后呢
我们这呃时间的场景是回看12个时间戳
然后预测下12个时间戳
还要考虑到四个baseline
baseline
就简单的是r n t cn
然后呢呃这两个就是r n加graph conclusion
这个就是t cn加graph conclusion
其实呢它们对应的相关的有相关的论文发表
和这个gcn和gr u的组合
其实就是对应的是dc r n t cn和gcn的组合
其实对应的是graph net
然后呢我们就基于此啊
我们做了啊三个三类增强吧
第一类增强就是我只去做啊
时间那个维度的增强
就是让不同的时间序列
能够有一个自己独特的一组啊模型参数啊
就是用只用这个d f g n去做增强
我们标注为d和r n和d t cn
那第二个呢
就是只用这个动态的相关矩阵进行增强
那他就是d a r n和d a t c
那第三个呢就是我既用d f g n
又用d m g d a m g n去做两个同时去做啊
时间维度的和这个相关性
动态相关性的维度的增强
然后他们是标注为d d a作为一个前缀
然后这里呢我们可以看到
首先是看这个d f g n的这个这个效果
我们可以看到
不管是r n家族还是t cn家族
我们通过这个加强之后呢
总是比他不加强的这个呃对应的那个版本呢
是要能够有更精确的一个呃一个效果啊
在三个不同的时间
三个不同的这个数据集上
都进行了一个一个验证
然后接下来就是对这个呃
d a m g n的一个一个
和这个两个plugin neural一起的一个验证啊
这里面也可以看到呢呃在大部分情况下啊
是当我们同时用这两个增强网络的时候
它的效果是最好的
然后呢最后我们又对呃
呃当前的sota也进行了一个综合的对比啊
这是我们看到的
基本上是我们增强过的某一种网络
可能是t cn
可能是rn呃
经过增强之后的网络呢
它能够达到最好的这个效果比啊
当时这个这文章当时是在2021年吧
就当时的最好的这几个贝斯呢
都是要能打败他们的
那另外呢就是又看到它一下
它的一个一个代价吧
就是我们因为我们加了一个两个小的这个
plugin network
它肯定是会呃让整个过程变慢
那我们分别做training time和prediction time
做了一个一个分析吧
然后看到training的时候呢
确实还有一个一个明显的变慢的过程
因为它啊多了一个plug in的一个network
虽然它是一个比较轻量化的一个小的一个网络
但是它与原始的模型相比的话
它还是多了一些可可需要训练的一些参数
所以呢他的训练过程是变慢了
但是呢呃在用的时候呢
因为我们训练好的这个plugin呃模型之后呢
当你用的时候呢
它是一个非常小的一个模型
然后呢它influence的时候呢
它对这个时间的影响可以看到是非常非常小的
然后可以支持一个实时的一个预测
然后呢最后呢我我们就是呃又去呃
把这个我们学习到的这个memory
然后进行了一个一个分析
其实你可以看到
这里面有一个非常有意思的一个一个例子吧
就是你可以看到这这是一个两条
相当于是高速路
一个是南北走向
一个是东西走向的
那你可以看到它学出来的这个memory呢
呃他是这个东西走向的
这几个传感器部署的位置呢
它是聚到了一起
然后呢这个呃南北走向的这几个传感器的这个
它们对应的memory也聚到了一起
但是虽然说他们这几个传感器
如果按distance来算了
他们其实是呃靠的还比较近的
但是呢因为他们因为一个是南北走向
一个是东西走向
他们的这个呃
空间上的变化规律应该是不一样的啊
所以呢是非常好的呃
把它两个两个走向的这个呃
车流量能够能够非常好的区分开来
这就证明了我们这个啊
通过对每个时间序列或者每个传感器呃
去学习一个小的memory
那确实能够捕捉到他们他们比较比较特殊的
或者独特的这个呃呃时间上的规律
同样这个也是一个一个相似的一个例子吧
就是他们这几个其实也是在呃
从distance上来看的话
从距离上来看
他们虽然是比较近的
但是呢他们的走向是不一样的
所以呢呃相同一条路上的这些传感器呢
都被聚到了同一个类
就说明他们的memory是学出来是比较像的啊
这样的话可以有效的能够区分这个东西走向和
南北走向的一个呃
一个不同的时间上的变化规律
然后呢这个是呃这个学习到的这个理解矩阵
我们可以看到啊
这个理解矩阵呢
你看到这个a矩阵就是呃
因为他们可能离得比较远
就是所以他们在这个只用这个呃
基于这个距离的临界矩阵的时候
他们就是没有没有任何的correlation
但是用了这个b矩阵之后呢
我们就学到了一些呃潜在的静态的相关性
但是呢这些相关性可能是跟你这个distance人
是完全不相关的啊
另外呢我们可以看到我们的c矩阵呢
也学学习到了一个非常有意思的情况
就是这是在两个不同的时间戳
那同样的情况下
这个地方呢是没有相关性的
但是在下一个时间时刻呢
他们的相关性就变强了
这个呢是这个前一个时刻
它有一些少许的相关性
但是在下一个时刻呢
它的相关性就完全的这个这个减弱了啊
这就是说明了我们这两个a bloody network呢
其实是达到了他想要的一个一个效果
那现在做一个稍微的总结
就是我们提出了两个呃ugin network
然后他们能够啊对现有的模型进行增强
第一个呢就是让让它可以更好的去捕捉
这个跟呃时间序列本身相关的
一个独特的这个呃啊空间特征
第二个呢它是时间的相关性
另外一个呢是它可以捕捉到动态的相关性
然后现在呢就是呃我们基于此之后呢
我们又想了一些啊
问了一下我们相关的一些问题
就是我们能不能能能不能继续做的更好啊
答案是肯定的啊
为什么这么说呢
就是我们可以从啊这这三个维度去考虑
就第一个维度呢
其实我们考虑的就是已有的大部分的模型
它可能就是时间和空间都是都是不相关的
就是它是用同样一套的
是这个模型参数去给所有的时间序列
然后我们现在做的其实是一个spatial awareness
就是在不同啊空间位置的传感器
我给它使用了一套全新的啊
全新的一个一个一个模型参数对吧
就是说我不同的d i的呃
传感器或者第i个时间序列
我对它有一个单独的建模
但是这个建模不是简单的去用更多的参数
而是用一个小的生成网络去生成的
那同那这样的带来的地同样的一个思考
一个一个相似的思考
就是我们是不是还应该有一个temple
就是呃跟时间相关的一个一个一个建模
它什么意思呢
就是我们这里不光是对啊
不同的传感器有一套相关的一个模型参数
我对不同的时间戳的时候
也同样有一个
还有独特的一个一个一组这个参数去捕捉
这里边
比如说我们可以看到
比如说这个呃传感器一和传感器二啊
他们啊其实你可以看到他在工作日和这个啊
非工作日就周末的时候
他们的这个呃呃时间上的这个动态关系
其实还是有不一样的
但是呢如果我们只对这个呃location
就是special让它进行一套建模的话
那我这个location一的时候
我第一个传感器它只有一套这个模型参数
去对它进行建模
但是呢它就可能很难去区分呃
工作日和非工作日
但是如果我们还有一个t这一类的话
那就相当于在不同的时间时刻
我们还有一独特的一套这个参数的话
那我们可能会捕捉这个呃时间和空间的相关性
可能会捕捉的更好
然后我们对这个相关的文献
作为一个有做的一个总结
其实我们可以看到大部分的方法呢
都是时间和空间不相关的
然后我们刚才提出来的这个enhance net呢
还有一些相关的其他文章呢
它是它是对这个呃十呃
空间这一位
对不同的传感器进行了一个独特的呃
模型参数的建模
然后有一篇文章的是对啊
空间啊
时间这一位做了一个建模
就是它在不同的时刻
它有不同的独特的一套模型参数去建模
但是呢我们这个方法呢是在呃对不同的呃
传感器
并且是不同的时刻
都用一个独特的模型参数
然后去进行建模
达到一个呃更啊
specific的所谓的时空感知的一个节目
然后我们这个方法呢其实跟刚才那个方法啊
是有那个异曲同工之妙吧
就是我们分了两两大部
第一大步呢就是对这个空间
这里呢我们还是用这个memory
就我们还是比如说这里面有三个时间序列
那我们就呃学习出来三个这个memory
然后这个memory是对不同的memory
是对不同的时间序列的
你这是时间这个时间这一维度啊
这是空间这一维度
然后对于时间这一维度呢
我们呃用一个呃回看一个时间窗
就是h的一个时间窗
然后呢
我们用一个encoder呢去生成它对应于z的一个
随着时间的一个变化
就是本身我我的这个呃
这个呃最常见的这个pattern呢
是由这个memory表示出来的
比如说第一条时间序列的话
就是z1 
但是呢当前t时刻呢
我可能会对我当前的这个这个pattern呢
是有一个有一个偏差的
那这个偏差是什么呢
就是用z t1 
就在t时刻
我第一个传感器的应该有一个什么样的偏差呢
我是通过这个当前的那你的数据
通过一个encoder
我去把它给把它进行一个建模
就是这个红色的小箭头
那之后呢我就可以把它俩加起来
就是本身呢以我这个时间
我这个传感器一应该是在这个位置
但是在这个t时刻呢
我最后一个偏差就偏差到了c c a t1 
然后呢从c的t一呢我就可以进行一个抽样
然后我用一个decoder
然后就可以把它对应的这个
模型的参数去生成出来
然后同样的对第二个和第三个传感器
我同样的是做一个它在呃时间
当前时刻下的一个小的偏移
然后偏移之后呢
我跟他原始的这个memory进行一个加和
然后我也可以进行一个sample
那就sample出来
就是它当前时刻下对一个呃
一个特殊的时间序列
我的一个表征
通过这个表征呢我可以生成它呃
跟你具体的呃预测模型相关的一些具体的参数
这样的话你就可以看到
我们现在就是
这是假设他未来的这个未来预测的这个模型呢
是啊
用的是transformer
所以他有q k q k v3 个三个矩阵
然后呢
这里面你可以看到它的上角标呢是对应的
是不同的时间序列
然后呢下角标t呢是对应于当前时刻
这样的话对当前时刻和不同的时间序列
我们都有一个特殊的这个模型参数
去对它进行一个建模
然后最后呢我们的实验也表明
在大部分情况下
通过这个时间和空间建模的
这个模型呢是能够达到一个最好的效果
ok啊我现在对这个第一个部分
我们做一个简单的总结
就是我们提出了不同的这个plugin network
它可以自动的去呃
提升现有的预测模型的一个一个效果
而且它呢是模型啊
agnostic model
agnostic
就是说它这个plugin network可以呃适配到啊
不管你的具体的forecast model用的是什么样的模型
我都可以去适配过去
然后呢
我可以有效地把这些呃
时间和空间不那么敏感的一个模型了
变成一个时间和空间啊敏感的一个模型
这样的话可以提高它的一个精确度
好
接下来呢我就去呃
呃讲一下我们第二个技术路线
第二个技术路线就是怎么样去啊自动的去啊
搜索或者说一个设计一个全新的啊预测模型嗯
这里面我们主要是通过
也是通过一个对现有工作的一个分析吧
我们啊有一个呃
有一个现有工作的一个基本的呃
现状的一个一个分析
现状的话
就是说啊现有的模型呢通常是有这么几个模块
第一个呢首先是一个embedding layer
然后呢最后有一层output layer
然后呢中间我是要去对这个s t blog
就是空间时间的一个blog进行一个堆叠
这里面举的两个例子
比如说这个a s t g进
它首先有一个哎embedding layer
然后他最后一个output的一个fully connected layer
那中间他的一个s t block呢
就是不同的t operator和s operatt operator
就是关于呃时间这边的建模
然后s这边呢
就是通过他的空间相关性的一个建模
in a graph net也是同样的方式
它有一个linear的一个embedding
然后最后一个linear output
然后它中间是有t cn和gcn的相关相关的组合
组合成的s t block
然后呢我们的我们的出发点就是呃
现在呢呃我们呃的一个出发点
就是我们现在去做这个s t blog的时候呢
同样是大家也是s t的一个啊一个一个组合啊
那我们可能人呢并不能找到一个最合适的组合
我们希望有一个算法
能够自动的去把s t这些operator
能一个最好的组合
能够能够组合出来
另外一个呢就是我们可能可以考虑到一个
更复杂的一个一个一个呃拓扑结构
比如说我们可能不是一个简单的堆叠
而是用一个复杂的拓扑结构
能够把它呃能够把它能够建模起来
就比如说这里面我们可能要走两条路
然后每条路上的它的s t blog
都是一个异构的s t blog
然后我们怎么做呢
我们就提出了一个auto c t s的一个一个框架
首先呢我们还是有embedding layer
然后output layer这里这个东西不变
然后呢我们中间设计了一个s t backbone
就是它的一个主干网
主干网呢它就是说我们这些不同的s t block呢
它的连接的拓扑结构是可以可以进行学习的
然后每一个s t block呢
它里面的呃具体的结构呢也是可以进行学习的
然后呢
我们这个主干网的是用一个所谓的microsospace来呃
来决定的
那个s st block是由一个micro search space来决定的
然后具体怎么做呢
我们可以看一看下来的具体的两个设计吧
就是micro micro usch space的话
我们是用了一个呃有线路环图
对它进行一个建模
然后呢这里面的h呢就代表一个表征
然后呢
这里面的边呢
就代表我所有可能出现的s t operator
比如说我们这里边的o一就可能是t cn o2 
可能是r n o3 
可能是graph convolution
然后这样的话我们就可以对它进行一个呃
一个有效的建模
比如说这里面从hi到hg
比如说从h0 到h2 
那我就是对这三个不同操作
我都可以对h0 进行一个进行一个操作
完了之后呢
我进行一个加权和
这就是从h一到h2 的一个转变
然后呢最后呢我们在呃某一个具体的节点呢
我可能是由呃若干个它前面的节点都可能过来
比如说h3 
我可能从h0 过来一只h2 过来一只
h一过来一只
然后呢我再用一个参数b的对它进行一个建模
就是也是类似的
也是做一个加权和
那加成和之后呢
就是我h3 的一个hg的一个区域的表征
然后我通过这样的一个建模
就可以把所有可能的这个这个呃模型的架构
都建模在这个所谓的这个micro dg里面去
这样的话我进行学习之后呢
我就可以对这个阿尔法参数进行一个选择模型
训练好之后呢
这个阿尔法每一个阿尔法
我去选择那个阿尔法最大的那条直路
比如说这个支路训练完之后
如果这条尺度最大的话
我就把这个这条阿尔法对应了这个操作
去保留下来
然后呢这个如果h0 和h2 之间
那是另外一条呢
那我就把它这个阿尔法对应的
最大的那个那个操作
然后把它保存下来
这样的话我就得到了一个
那从这个呃their space里面
就得到了一个它最优的一个网络的架构
然后这里面对s t operator的选择
我们也是进行了一个分类
就是对t operator我们进行了一个分类
有cn加速
r n加速和attention加速
然后我们发现了attention家族和cn家族
可能是比较优的
因为r n家族呢他有一个两个问题
就是他在建模这个长时间依赖关系能力不足
并且他比较慢
所以呢在用了attention和cn的情况下
我们就把r n就忽略掉了
最后我们选择的是g d c呃
呃get it deleted culture conution作为cn的代表
然后呢一个informance为attention的代表
另外对这个s operator
我们也考虑到gcn就是graph convolution和attention
然后分别选择了他们对应的一个呃具体的操作
然后micro suspace呢主要是对这个学习出来
是s t block之间的一个拓扑结构进行一个学习
它同样的道理呢
就是跟类似于刚才那个b的参数
我对这个不同的s t blog过来之后呢
对它进行伽马进行一个加权和的一个操作
然后最后呢也是取他伽马最大的那一只
保留下来
这就是它最后的一个拓扑
学出来的一个拓扑结构
然后呢现在我们就需要继续进行一个优化
这个优化其实跟传统的这个back propagation
是相似的
只不过我们现在要进行两个级别的优化
第一个级别呢是其实我最想得到的是
这个是这个sa
就是阿尔法贝塔和伽马是关于它的结构的参数
另外的一个呢是它呃
这个模型里面的具体模型参数
比如说这个conclusion的这个filter的这个参数
是怎么学到的
这样的话我就建模成了一个by level
optimization的一个一个问题
呃
首先呢它的外层优化呢
是说在validation data上去做
我希望得到一个最优的结构
这个最优的结构呢是用到了这个结构下
最优的一个呃模型参数
然后这个模型参数是什么呢
这个模型参数就是在给定这个结构的情况下
我在training data上得到的最好的这个模型参数
就是它这个所谓的w星
然后这两个进行一个交替的优化
最后呢我就可以得到一个最优的theta
最优的theta得到之后呢
我就可以导出一个呃
最佳的一个一个一个模型出来啊
我们在不同的数据集上也做了一些呃
相关的实验
我们可以看到我们凹凸c t s呢
就是它这个自动化设计出来的模型呢
它可以完美的打败现有的已有的模型啊
并且呢你可以看到啊
在第二名的
第二名的第二
好的这个这个成绩呢其实是有不同的呃
手工设计的网络来保持的
这就说明很难有一种呃手工设计的网络
它能够在不同的数据集
不同的任务上
我们表现的完全超越呃
呃特别的特别的完美
在这种情况下
就需要一个自动化的一个设计方案
在不同的数据集
不同的场景下进行一个一个建模
找到它最适合于某一个呃这个呃数据集
和某一个场景的一个一个任务
然后这里面是一个我们看到一个case study
就是在pm 04的这个啊数据集上
我们最后得到的是有四个不同的s t block
你可以看到他们啊使用了不同的s t啊
的这个operator
比如说这里面用到的是呃有identity啊
有informer
还有这个t cn
但是这个里面呢就没有用到相关的一些呃
比如说他就没有用到rtcn的操作
然后呢最后呢你可以看到他们这些s t blood呢
之间也是通过一个比较复杂的拓扑结构呃
进行了最后的输出
而不是通过一个简单的这个堆叠的情况
堆叠的形式进行一个呃一个一个输出
然后呢
这呃我们也进行一个呃比较简短的小结吧
就是auto c t s它是一个能够自动的呃发现啊
一个比较合适的cp破坏model一个方式嗯
它是通过了一个呃比较紧凑的一个operator set
就是通过对t opera和s opera operator分别的建模
找到一个比较小的一个一个操作集
这样的话可以让它的效率提得更高啊
另外呢就是呃我们提出了两种search space
能够分别对这个s t block的这个拓扑结构呃
和它对应的操作
和s t backbone的这个网络结构进行一个啊
进行一个选择
那同样的
同样的问题就是我基于这个凹凸c t s
我们能不能做得更好
然后其实这个答案也是肯定的
这个就是我们考虑得到的呃
两个点吧
第一个点就是这个前面这个凹凸cp
他其实没有考虑到超参数啊
我们只是对这个网络架构的一个搜索
那我们一个比较直接的啊
这个提高的方式呢
就是能不能通过这个超参数
和这个网络架构的一个联合搜索
然后达到一个找到一个
不光是最合适的一个网络结构
并且是他对应的一个相关的超参数
另外的话就是它的这个memory是一个消耗
是一个非常大的
因为这个super net是非常大的
就是啊super net就是指这个这个网络
这个这个网络
当你这个可以可供你选择
这个operator比较多的情况下
比如说你有十个operator可以选择的话
那其实这每一条边都要去做这十个操作
然后这里面又把所有可能的这个呃
这个这个从一个你前面的一个hidden representation
到后面的representation
都要去进行一个一个全部全连接的一个操作
让每一个连接其实都是包含了所有的这个
可能的操作
这样下来的话
这个这个网络其实是一个非常大的网络
它对内存的消耗嗯是非常大的
它是一个memory不是很友好的一个方法
那我们就提出了一个新的一个啊一个方法
他的啊叫做auto c t s加
他的一个思想就是我有一个联合搜索空间
它不仅有aitecture啊
并且他也有超参数
然后呢我这个联合操作空间之后呢
我就可以每次呢随机做两个sample
然后sample出来两个架构和超参数的一个对
然后呢对这两个这两个
这其实架构和传承素的对呢
其实就是一个具体的一个啊预测模型
那我对这两个两个具体的预测模型呢
我进行一个对比
然后看看谁的谁可能呃带来的效果好
然后通过这个这个对比器去进行一个对比
然后呢最后呢我就不停的去sample
不停的去sample
然后我用这个对比器呢不停的去对比
不停的对去对比
然后最后呢我比如说我就可以找到啊
top 3啊或者top k
这里面top k可能就比如说top一或者top 3呢
他的这个呃architecture和hyperparameter这个对
那就是它的模型
然后最后呢我们就把这个最好的这个对拿出来
作为它最终的模型去使用
呃
这里面的join the space呢其实也也比较直观啊
就是我们有一个architecture suspace
这里面就需要包括我们可能用哪些operator
然后他们之间的拓扑连接是什么样的
然后呢
hyperparameter呢
我们就可以考虑到不同的hyperparameter
比如说我这个模型里面应该有几个s t block
然后我这个每个t blog里面可能有几个呃
几个几个隐藏
然后隐藏的这个这个呃这个维度是多少等等
然后呢
我对每一次我都可以从这个architecture space里面
抽出来一个对应了一个网络架构
然后我从这个hyperparameter里面
可以抽出来一个hyperparameter的
一个一个一个vector
然后呢我对它进行一个综合的建模
就是把它还是变成一个一个图结构
然后呢通过这个图截后呢
我去串一个啊对比器
然后呢
也就是说呃我让这个对比器去做一个判断
就看这两个这两个模型
可能哪个模型的效果会更好
然后呢
我就用这个对比器训练好之后的这个对比器呢
我就可以去呃做呃
对这个联合搜索空间不停的去抽样
然后去做对比
然后呢
这三代的关键呢就是怎么样去呃训练
这个呃模型的这个对比器
然后我们提出了一个嗯下面一个策略吧
就是我们首先要找到如果去做对比的话
我们首先要知道就是这个这两个呃这两个模型
它的它的效果到底有多好
那我们首先呢
就是说我们要把这两个模型要撑到啊
充100个epod
或者说就冲到底
然后得到他们的精确度
然后呢看到他俩谁好的话
就是说比如说这里可以看到是a h1 
b h a h2 要好
那么a h一和h2 就是对应一个正立
然后呢但是呢如果我对每一个模型啊
都要去做一个一个冲到底的操作的话
那我就为了采集这样的训练样本的话
我都会时间会更长
但是呢其实我们其实并不care
我们并不关心他们最后的这个精确的
它的它的预测效果是多少
而只是我们只是
我们只是希望得到一个他们俩谁好谁坏
那这样的话我们就呃考虑到一种
用一个noisy sese的一个呃一个方法
那它是什么意思呢
我就不用吹到吹到底
我要他训练五个e poke
然后我就可以看到一个大概看看谁好谁坏
然后这种情况下呢
我就可以非常快的得到一个
他们之间的一个training data
就是呃一个给两个啊这个模型呃
呃这个给两个这个呃预测模型
我们可以呃大概的知道他俩谁好谁坏
然后呢我们可以去得到大量的这样的
很快的得到大量的种子
然后呢对它进行一个训练
然后呢
在最后最后呢用一个少量的这个干净的种子
对它进行一个饭听
这样的话就可以高效的去训练得到这个对比器
然后基于此呢
我们也做了相关的实验
我们可以看到这是两个不同的场景下的
auto c t s加
我们可以看到auto c t c to c t s加是可以啊
比这个auto c t s啊表现的更好
然后这里可以看到他们的memory cost啊
auto s auto c t s加
和这个比这个auto c t s和auto s t g
auto s t s t g是另外一个自动化的呃
设计的啊
设计的方法
他们前面两个其实都用的是那个前一种
super net的方法
他们的他们的内存
随着这个呃啊呃
这个时间序列的个数和
随着这个预测的窗口的增加的增加了
它们增长是非常快的
而我们这个奥图cd s加呢
它的呃几乎是维持了一个一个一个constant
一个普遍的一个量
然后可以看到我们学到的这个模型
也是更具有diversity吧
就是这里可以看到
我们这里边其实用到了七个呃hidden states
然后另外一个场景下的模型呢
我们只用到了一个呃五个hidden states
这就主要是由于
那我们能够对超参数进行一个联合的搜索
可以对不同的场景
能够得到一个完全不同的这个呃网络架构
最后呢
我对这个我们的这个今天这个top
做一个大的总结吧
就是我们提出了两种技术路线
第一种技术路线呢就是通过啊plugin network
去对已有的模型进行一个增强
然后呢
第二个技术路线呢
就是通过啊两种不同的自动化
在这个啊framework去设计全新的预测模型
这里面呢主要是说怎么样啊去全新的设计啊
神经网络架构以及它对应的一个超参数好
最后呢我我想再花两分钟
对我们这个学院的近期进行的这个呃
研究生招生做一个一个小的广告吧
就是啊华东师范大学数据科学与工程学院好
我们再进行这个
马上要进行这个优秀大学生夏令营啊
主要是面向啊具有保研资格的啊这个本科生
然后呢
他的时间是在今年的7月17号到19号啊
形式是线下啊
我们的报名截止日期呢还有一个多月的时间
就是如果有相关的学生感兴趣的话啊
请这个我们积极的报名
然后我们学院的这个整体的理念是应用驱动
创新和开放成就创新啊
我们有两个大的专业
一个是数据科学与工程
他招收的是学术型硕士和博士
然后大数据技术与工程专业
是招的是专业硕士和专业博士
然后主要的研究方向主要是两大块
第一个是人工智能
就跟智能相关啊
第二个是跟系统相关
主要是数据库系统和和区块链基础
然后呢
我们现在我现在所在的实验室是这个角色
智能实验室
它主要是对呃复杂异构的数据
包括时间序列
时空数据图啊
图像分子结构进行分析和管理啊
主要的应用场景就包括了跟我们six special啊
相关的智慧城市啊
绿色交通啊
还有数字能源
然后我们主要的研究有
现在主要集中在四个点吧
今天就包括今天我们讲的这个自动化啊
除了自动化之外呢
我们还哎主要考虑的是可解释性
健壮性以及轻量化好
我们现在有四位导师啊
包括我自己还有呃郭春娟老师
胡胡敬林老师
还有舒娟老师啊
我们是拥有一个呃比较好的一个导师团队啊
包括一名国家级领军人才
和两名国家级青年人才
然后我们同时还在招啊
博士后和专职研究人员
就是如果有感兴趣的同学的话
也可以啊更多联系
然后除此之外呢
我们学校还有一位啊毛佳丽老师的团队
他跟我们这个啊six special的相关的研究方向
也是非常相关的啊
他的研究方向主要是包括施工
数据管理与分析啊
数据驱动的物流决策优化等啊
他也在最近获得了非常多的一个奖项啊
对这就是我今天想跟大家分享的
关于这个时间序列分析
尤其是时间序列预测自动化的一些相关的内容
好谢谢大家好的
非常感谢这个杨老师啊
这么细致哈
讲的非常非常细致
这呃直接这个把这个网络的这个这个性质结构
都偷偷讲得非常清楚啊
啊听得呃应该说学习到了很多
因为我们这个团队也有同学们在做相关的
这样的一些研究
所以我刚才听您的这个报告的时候
也马上跟我的学生说
你赶快呃
这个来听一下这个这个杨斌老师的这个讲座
不过还好我们就有录像
有p p t
待会我们后边还会进一步的仔细的学习
这个杨老师的这个呃成果啊
要是这样
这个我们的工作人员呢
会把这个各个平台上收集起来的问题呢啊
共享到屏幕上
您可以这个看看呃
然后选择性的做回答好吧
好的好的啊
这这个第一个第一个问题
其实其实是呃考虑过的
就是如果是简单的去对每一个时间序列呃
做那个单独的建模的话
可能是会造成过拟合的
这就是我们为什么呃
采用了这个一个声小的一个生成网络
而是对每一个时间序列只用一个小的memory
然后从这个memory呢通过这个生成网络去生成它啊
相关的一个一个模型参数
通过这样的一个方式去
避免了这个过拟合的一个一个发生
然后dd a m g n对应对每个时间窗口啊
那这个这个其实呃嗯嗯
同样的问题就是
我们不是仅仅的只用这个d a m g n
它生成的这个呃凝结矩阵去对它呃
作为一个呃操作
而是说我们它只是一部分吧
就是它其实是a b c的相加
就是其对于distance啊
做得出来这个临界矩阵的一个一个小的直邮证
而不是说我仅仅的就用这个d a m g n
它生成了这个c矩阵去做啊
去做这个呃graph conclusion
所以从这种这种角度来说的话啊
其实他是不会啊
呃一定程度上去避免了可能过拟合的发生吧
而不是一个完全自主学习出来的
如果是完全自主学出来的话
那他可能会更容易去造成这个过滤盒哦
自动化这个等泛化性
这个确实是个是个可能一个一个问题吧
就是呃可能就是我们嗯
就是刚才实验里面也提到了
就是他的一个初衷
或者说它的一个优势
可能就是说我要得到一个呃对一个数据集
或者对一个场景
他要搜索出来一个最最最合适的这个模型
但是对它的模型泛化性来说的话
我们确实没有做更多的考虑
但是我们也做了一些初步的实验
就是呃比如说你在a数据集上搜出来这个模型
你放到b数据集上去用
它当然也可以用
但是它肯定是没有在b数据集上
你去单独再搜出来一个模型
跟它相比的话
肯定是不如不如他的
就是从这个角度来说的话
就是可能泛化性并不是这个自动化这个路线
他所追求的吧
就是自动化
可能还是说对一个具体的问题
或者一个具体的数据集
我能够得到一个呃特别特殊的
或者说specific的一个一个模型
而而不是说我要得到一个呃generic的模型
当然当然就是现在随着这个大模型的出现吧
就是可能呃这个可能跟大模型有点怎么说呢
呃有点可能不是特别一致吧
所以说现在也有也有我们也在考虑
就是能不能去自动的去设计一个啊
可能泛化性更好的一个一个一个基础模型啊
而而不是说对
就是现在我们考虑的是对一个具体的场景
一个具体的时间啊
时间序列的数据集去做一个呃
具体的具体的这个设计
呃可解释性在凹凸c t s里边
可能啊表现的不是特别强吧
就是还是怎么说呢
基于这个黑盒的优化去去选的这个
它它到底从第一层到第二层
他用什么操作
并没有可能呃更多的一个可解释性吧
啊多模态其实我们也有考虑
就是呃但是现在就是多模态数据跟啊
比如说我我我现在的那个就前面讲到那个memory
其实我就是假设它是一个可能呃
一个隐隐藏的一个一个特征对吧
但是这个时候其实如果我有这个呃
传感器部署的空间的周边的一些信息
比如说我有什么遥感遥感图像呀
我我可能通过这个遥感图像
我去可以更好的去生成它这个它这个memory
那这个可能就是一个呃跟这个js可能相关的呃
就是js相关的一些呃上下文信息
我可以更好的融入到这个呃
传感器部署的位置周边
然后这样的话我可以作为一个原信息
对他进行更好的建模
这样的话肯定是可以提高对时间序列
尤其是跟这个空间相关的时间序列的预测的
当然还有一些呃
就是多模态数据可能不光跟图像遥感图像啊
或者说跟啊其他的一些
比如说比如说自然语言啊
我我要去进行
比如说呃这种交互式的时间序列分析
或者说异常检测
我可能说我要我要
我要检测一个什么样的一个异常
或者说我想检测一个什么样的一个一个pattern
这种结合可能也是比较呃比较有趣的吧
但但是我们现在还没有具体的去展开呃
时间序列呃
以时间序列为基础的多模态
多模态数据的一个研究
我觉得这是一个比较有趣的方向
但是可能他的一个难点是如何获取这种呃
呃对应的这个呃多模态数据吧
就是你可能有有你有那个呃遥感的图像
但是你没有这个遥感图像对应的时间序列
或者你只有时间序列
但是没有这个时间序列部署的
那些传感器位置的对应的这个呃遥感图像
这样的话
如果你没有对齐的呃
两模态数据或者三模态数据
也很难去排展这个动模态数据的数学的研究
好的这个非常感谢杨斌老师啊
那个我们的工作人员可以退出了啊
我把这个屏幕再共享一下