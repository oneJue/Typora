间隔最大使它有别于感知机

![image-20231012150657176](./assets/image-20231012150657176.png)

## 函数间隔和几何间隔

### 函数间隔

![image-20231002235835637](./assets/image-20231002235835637.png)

+ 缺陷：函数间隔可以表示分类预测的正确性及确信度。但是选择分离超平面时，只有函数间隔还不够。因为只要成比例地改变w和b,例如将它们改为2w和2b,超平面并没有改变，但函数间隔却成为原来的2倍。这一事实启示我们，可以对分离超平面的法向量w加某些约束，如规范化，w=1,使得间隔是确定的。这时函数间隔成为几
  何间隔（geometric margin）。

### 几何间隔

![image-20231003002804445](./assets/image-20231003002804445.png)
## 间隔最大化导出优化式
<img src="./assets/image-20231002012541517.png" alt="image-20231002012541517" style="zoom:150%;" />





`支持向量`：在线性可分情况下，训练数据集的样本点中与分离超平面距离最近的样本点的实例称为支持向量(support vector)

### 例子

![image-20231003004316887](./assets/image-20231003004316887.png)

## 学习的对偶形式

![image-20231003004551021](./assets/image-20231003004551021.png)



### 例子



![image-20231003011256828](./assets/image-20231003011256828.png)
上面的式子理解成关于$\alpha$关于x的内积的二次型
![image-20231003011314523](./assets/image-20231003011314523.png)



-----



![image-20231003013610455](./assets/image-20231003013610455.png)

## 软间隔

![image-20231012154219685](./assets/image-20231012154219685.png)
