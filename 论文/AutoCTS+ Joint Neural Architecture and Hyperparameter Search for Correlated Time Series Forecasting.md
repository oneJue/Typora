## AutoCTS+: Joint Neural Architecture and Hyperparameter Search for Correlated Time Series Forecasting
相关时间序列(CTS)预测在许多网络物理系统中发挥着重要作用,其中多个传感器发出捕获相互关联过程的时间序列。基于深度学习的解决方案提供了最先进的CTS预测性能,它们采用了各种时空(ST)块,能够对时间序列的时间依赖性和空间相关性进行建模。然而,仍然存在两个挑战。首先,ST块是手动设计的,这是耗时且昂贵的。其次,现有预测模型只是简单地多次堆叠相同的ST块,从而限制了模型的潜力。为解决这些挑战,我们提出了AutoCTS,它能够自动识别高度竞争力的ST块,以及由异构ST块连接且拓扑结构多样(而不是堆叠相同ST块)的预测模型。具体来说,我们设计了微观搜索空间来对ST块的可能架构进行建模,以及宏观搜索空间对异构ST块之间的连接方式进行建模,并提供了一种能够联合探索这两个搜索空间以识别最优预测模型的搜索策略。在八个常用的CTS预测基准数据集上进行的大量实验证明了我们设计的合理性,并表明AutoCTS能够自动发现优于人工设计模型的预测模型。这是"AutoCTS: 自动相关时间序列预测"一文(将发表于2022年PVLDB)的扩展版本。



1 引言

我们目睹了网络物理系统(CPS)中传感器技术的不断发展,传感器产生大量相关时间序列。例如,在交通运输领域,嵌入道路的交通传感器会发出多个交通时间序列,记录不同位置的交通流量随时间的变化。由于一条道路上的交通流量通常与附近道路的交通流量相关,因此这些交通时间序列往往是相关的。对相关时间序列进行预测在确保CPS有效运行方面发挥着重要作用,如识别趋势、预测未来行为和检测异常值。例如,交通时间序列预测可以改善交通系统中的车辆路由。

通过考虑时间序列中的时间依赖性和不同时间序列之间的空间相关性,最近的深度学习模型在相关时间序列预测任务上展现出了令人印象深刻的最先进性能。时间依赖性捕捉了历史值如何影响未来值。我们使用"空间相关性"一词,因为不同时间序列之间的相关性通常是由于产生这些时间序列的传感器部署位置的接近性,但相关性也可能由于其他因素引起。更具体地说,相关时间序列被建模为一个时空(ST)图,其中节点表示时间序列,边表示成对时间序列之间的空间相关性。

基于上述ST图建模,提出了不同的模型来实现预测。图1(a)总结了现有的预测模型,它们通常包括(1)一个嵌入层,将输入时间序列数据转换为嵌入表示;(2)一个ST主干网络,由多个能够从嵌入时间序列数据中提取适当的时空特征的ST块堆叠而成;(3)一个输出层,基于ST主干网络提取的特征产生最终预测。

不同的研究提出了独特的ST块,负责捕获时间依赖性和空间相关性。例如,STGCN采用了一种"三明治"ST块,包括两个时间卷积(用于建模时间依赖性)和中间一个图卷积(用于捕获空间相关性)。

虽然提出了各种预测模型,并且最先进的精度不断提高,但仍存在两个主要限制。

第一,ST块是人工设计的。现有研究依赖人工专业知识来设计有效的ST块,这既低效(通常需要数周或数月时间),又昂贵。此外,由于存在大量能够捕获时间依赖性(T-算子)和空间相关性(S-算子)的算子,设计ST块的搜索空间非常大。因此,人工几乎不可能识别出T/S算子的最优组合,从而可能错过了高效的ST块。此外,机器学习的快速发展可能会导致新的、具有竞争力的算子被发明出来。为了从新算子中获益,有必要在新算子出现时重新进行低效且昂贵的人工设计过程。此外,由于不同领域的时间序列具有不同的特征,很难设计在不同数据集上表现良好的ST块。因此,需要一种自动化设计过程,能够从可配置的T/S算子搜索空间中为特定数据集识别出最优ST块。

第二,ST主干网络是通过简单堆叠同一种ST块来构建的。我们假设由异构ST块连接而成的具有灵活拓扑结构的ST主干网络(如图1(b)所示)有潜力产生更高的精度。不同的ST块可能提取不同的特征,从而可能对时间序列产生更多样化的表示,进而提高精度和稳定性。支持多种拓扑结构提供了额外的灵活性,从而有助于实现多样化模型。然而,考虑由异构ST块构成的具有灵活拓扑的主干网络会增加模型设计时的搜索空间,因此人工设计变得更加困难和耗时。这自然需要一种自动化设计方法。

尽管神经架构搜索(NAS)技术能够在计算机视觉和自然语言处理等任务上优于人工设计的模型架构,但现有的NAS方法无法解决上述两个限制。第一,对于相关时间序列预测任务,没有明确定义的搜索空间,因为现有NAS方法通常集中于计算机视觉和自然语言处理。直接使用为其他领域设计的搜索空间无法识别出具有高潜力的ST块来捕获时间依赖性和空间相关性。直接使用文献中所有现有的S/T算子会产生一个极其庞大的搜索空间,从而使得识别有前景的ST块变得非常困难和耗时。

第二,大多数现有NAS方法侧重于识别最优的单元(cell),例如在我们的设置中的ST块,同时假设了连接多个相同单元实例以构建最终模型的固定拓扑结构,例如按顺序堆叠相同的ST块(如图1(a)所示)。这无法解决手动设计预测模型的第二个限制。

我们提出了AutoCTS,不仅能够自动设计ST块,而且能够自动设计由异构ST块按复杂拓扑连接而成的ST主干网络,从而解决上述两个限制。为创建AutoCTS,我们首先设计了一个微观搜索空间,针对ST块建模了算子以及不同算子之间的连接方式(使用图表示)。为实现有效和高效的搜索,我们根据对现有手动设计的ST块的彻底分析,审慎地选择了一组紧凑的T算子(用于建模时间依赖性)和S算子(用于建模空间相关性)。这使我们能够在所提出的微观搜索空间中自动识别出高度竞争力的ST块,从而解决了第一个限制。接下来,我们提出了一个宏观搜索空间,以及一种联合搜索策略,允许在异构ST块之间搜索最优拓扑。这解决了第二个限制。

据我们所知,这是第一项系统研究自动化相关时间序列预测时空块和主干网络的神经架构的工作。本研究做出了三方面贡献:

首先,我们精心设计了相关时间序列预测任务的微观搜索空间,包括T算子和S算子,以及能够从微观搜索空间中识别出最优ST块的搜索策略。

其次,我们提出了一个宏观搜索空间,以及一种联合搜索策略,不仅能够搜索ST块,而且能够搜索具有异构ST块灵活拓扑连接的预测模型。

第三,我们在来自不同应用领域的相关时间序列数据集上进行了大量实验,从而获得了对我们设计选择的见解和理由,同时也证明了我们的方案能够优于现有最先进方法。

论文的其余部分安排如下。第2节介绍了preliminaries概念。第3节详细阐述了所提出的AutoCTS框架。第4节呈现了实证研究。第5节讨论了相关工作。第6节给出结论并提出了未来工作方向。

2 preliminaries
我们首先介绍相关时间序列预测的概念,阐述了本文提议所需的概念,并正式定义了问题。

相关时间序列 考虑N个相关的多变量时间序列X∈RN×T×F,其中每个时间序列覆盖T个时间戳,每个时间戳有F个特征。例如,假设在一个道路网络中部署了100个传感器,每个传感器每5分钟报告一次行驶速度和交通流量。那么对于一天,我们就有一个相关时间序列X∈R100×288×2,包含N=100个时间序列,覆盖T=288个时间戳,每个时间戳有F=2个特征。我们用X(i)∈RT×F表示第i个时间序列,其中1≤i≤N,用Xt∈RN×F表示在时间戳t处所有时间序列的特征值,其中1≤t≤T。

为了对不同时间序列之间的空间相关性进行建模,我们引入一个图G=(V,E,A),其中每个顶点V对应一个时间序列,因此|V|=N,边集E表示不同时间序列之间的空间相关性,邻接矩阵A∈RN×N包含边的权重,反映了时间序列之间空间相关性的强度。这些边权重可以是预先定义的,例如基于产生时间序列的传感器位置之间的距离,或者通过数据驱动的方式学习获得。

相关时间序列预测 我们同时考虑单步和多步相关时间序列预测的情况。给定过去的P步,(1)对于单步预测,我们预测未来第Q步,这里Q≥1;(2)对于多步预测,我们预测总共Q个未来步骤,这里Q>1。我们形式化定义单步相关时间序列预测问题如下:

X̂t+P+Q = Fw(Xt+1, Xt+2, ..., Xt+P; G)

其中Fw是预测模型,w是其可学习参数;X̂表示预测值。类似地,多步相关时间序列预测问题定义如下:

{X̂t+P+1, X̂t+P+2, ..., X̂t+P+Q} = Fw(Xt+1, Xt+2, ..., Xt+P; G)

问题定义 本文的目标是自动识别一个精确的预测模型Fw。这包括识别(1)描述模型F的架构参数θ,例如在不同时空块中使用哪些运算符,以及不同的时空块在时空主干网络中是如何连接的;和(2)在不同运算符中使用的模型参数w,例如卷积运算符中的卷积核,注意力运算符中的投影矩阵。目标函数如下所示:

argminθ,w ErrorMetric(Fw, D)

其中ErrorMetric(Fw, D)返回模型Fw在训练数据集D上的预测误差。3 自动化相关时间序列预测

图2概述了自动化相关时间序列预测框架AutoCTS,它包含三个主要组件 - 嵌入层、ST-backbone学习层和输出层。嵌入层将原始时间序列输入特征X映射到高维表示Z,以促进从输入时间序列提取更丰富的特征。

ST-backbone学习层是AutoCTS的核心组件,能够自动设计包含异构ST块的ST-backbone(如图2(b)所示),其中异构ST块的设计也是自动化的(如图2(c)所示)。在搜索ST-backbone时,我们使用参数γ来参数化不同ST块之间的连接。例如,γ(4)控制来自ST块b1、b2和b3的三个连接如何连接到ST块b4。在搜索ST块时,我们同时搜索(1)两个表示之间的算子,由α参数化,以及(2)不同隐藏表示之间可能的不同连接,由β参数化。例如,α(0,3)代表ST块b2中隐藏表示h0和h3之间的算子,β(3)代表ST块b2中隐藏表示h0、h1和h2如何连接到隐藏表示h3。我们使用独特的参数集{αi,βi},使得异构ST块可以被识别。自动设计的ST-backbone将从嵌入层获取高维表示Z作为输入,并提取时空特征,这些特征被输送到输出层。

最后,输出层进行预测X̂。我们使用损失函数(如均方误差)来衡量预测值与真实值之间的差异,从而实现学习。

在下文中,我们首先确定适当的搜索粒度(3.1节),然后介绍微搜索空间的设计用于ST块(3.2节)和宏搜索空间用于ST-backbone(3.3节)。最后,我们提出一种搜索策略,能够联合探索微观和宏观搜索空间,从而发现有前景的预测模型(3.4节)。

3.1 搜索粒度
搜索空间可以基于不同粒度的操作构造。基于细粒度操作的搜索空间提供了更大的灵活性和识别人类专家无法识别的有前景神经架构的机会,但它通常也产生了一个非常大的搜索空间,搜索过程需要大量时间和计算资源。相比之下,基于粗粒度操作的搜索空间产生了较小的搜索空间,从而加快了搜索过程,但它也可能引入人为偏差,阻碍了识别出高性能架构的可能。

更具体地说,在我们的问题环境中,存在三种不同的粒度。从粗到细,依次是ST块、S/T算子和基本计算。我们先用一个具体示例介绍这三种粒度,然后讨论选择适当搜索粒度的设计选择。

图3显示了人工设计的预测模型 Spatio-Temporal Graph Convolutional Networks (STGCN)[51]的神经架构。STGCN的backbone由两个堆叠的ST块组成(参见图3(a))。一个ST块包含三个S/T算子 - 两个T算子(即门控卷积算子)和一个夹在中间的S算子(即图卷积算子)(参见图3(b))。一个S/T算子通常包含多个基本计算。例如,图3(c)显示了门控卷积(即T算子)的架构。这里,I和σ分别指代恒等函数和sigmoid函数;Conv是卷积算子,×是元素乘积。这些都是基本计算。

基于上述情况,最粗粒度的搜索粒度是使用现有的人工设计ST块作为搜索空间中的原子搜索单元,以找到新颖的ST-backbone。例如,除了使用如图3(a)所示的堆叠同质ST块结构外,还可以搜索具有更灵活结构的ST-backbone,其中包含许多不同的人工设计ST块,如图1(b)所示。然而,由于人工设计的ST块可能已经包含了人为偏差,仅搜索它们之间的不同连接可能会限制发现新颖且高性能backbone的机会。

下一个粒度是使用人工设计的S/T算子作为原子搜索单元来搜索新颖的ST块。由于S/T算子的粒度比ST块更细,这种粒度为发现超越现有人工设计模型的更强大预测模型提供了更大机会。另外,每当设计出新的S/T算子时,新算子都可以轻松地纳入搜索空间。我们认为这是一个适当的粒度。

最细的搜索粒度是使用基本操作作为原子搜索单元来搜索新颖的S/T算子。然而,这比使用S/T算子作为搜索空间单元导致了更大的搜索空间,需要过高的计算成本,并且需要非常大的数据集才能进行有效训练[32]。

为了发现高竞争力的预测模型,且不需要高计算和内存成本,我们选择使用S/T算子作为所谓的微搜索空间中的原子搜索单元来发现新颖的ST块。接下来,在宏搜索空间中,我们使用自动学习的ST块作为原子搜索单元来确定具有灵活结构的新颖ST-backbone。

3.2 微搜索空间
微搜索空间定义了可被发现的ST块的可能架构。我们首先介绍微搜索空间的设计,然后解释如何减小微搜索空间的大小以加快搜索速度。

3.2.1 微DAG。我们假设一个ST块包含M个潜在表示。第一个潜在表示是来自嵌入层或另一个ST块的输出表示。另外,我们考虑一组算子O,例如包括多个S/T算子,能够将一个潜在表示转换为新的潜在表示。

我们将微搜索空间表示为一个有向无环图,称为微DAG(见图4)。微DAG有M个节点hi(0≤i≤M-1),每个节点表示一个潜在表示。节点h0表示由嵌入层返回的表示。对于每个节点对(hi,hj),我们有|O|条边,每条边对应于算子集O中的一个算子。图4(a)显示了一个示例,其中O={o1,o2,o3}包含三个算子,因此每个节点对都有三条边相关联。另外,我们只包括从节点hi到hj的边,如果i<j。这使得图形成一个DAG,模拟了训练神经网络时的前向流程。

图4(b)显示了从微DAG派生的一个ST块,它是微DAG的一个子图。具体来说,派生的ST块在每个节点对(hi,hj)之间只保留一条边,即一个算子。另外,对于每个节点,它最多保留两条入射边。这允许ST块具有相对复杂的内部拓扑结构,并避免引入过多参数。

微DAG表示了具有M个潜在表示的ST块的所有可能架构,共有M(M-1)/2种。然而,微DAG的大小随着M的增长而呈指数级增长。为了降低搜索成本,我们需要减小微DAG的规模。



3.2.2 减小微搜索空间。为了使搜索更高效,我们采取了两种策略来减小微搜索空间的规模。











首先,我们通过仔细分析现有人工设计的ST块来限制算子集O的大小。具体来说,我们考虑了8种广为人知的人工设计ST块:GWN [46]、STGCN [51]、DCRNN [16]、MTGNN [53]、AGCRN [47]、STSGCN [11]、PEMS-STGCN [9]和PMGR[29]。我们总结了它们使用的所有不同T/S算子,整理成一个简洁的算子集O,如表1所示。O由8个算子组成:卷积Conv、门控卷积GatedConv、GraphConv、注意力Attention、TemporalAttention和DenseLayer等。

其次,我们限制ST块中的最大潜在表示数量M为6。我们分析了上述8种人工设计ST块,发现它们最多只包含6个潜在表示。因此,将M设置为6可以确保我们的微搜索空间能够涵盖现有人工设计ST块,同时保持微搜索空间的规模可控。

通过上述两个策略,微搜索空间的最大大小降低到C(6,2)×8^5=92,160种可能的ST块架构,使得对微搜索空间的搜索变得可行。我们将在第3.4节介绍用于有效搜索微搜索空间的策略。

3.3 宏搜索空间
宏搜索空间定义了ST-backbone的可能架构。我们先介绍如何表示ST-backbone,然后描述我们的宏搜索空间。

3.3.1 ST-Backbone表示。我们将ST-backbone建模为一个有向无环图(DAG),其中每个节点表示一个ST块,边表示不同ST块之间的连接。我们使用NB表示ST块的数量,即图中节点的数量。

我们采用基于位置的ST块连接编码方案,即第i个ST块的输入受到比它编号小的ST块的影响。具体来说,对于第i个ST块bi,我们使用一个参数向量γ(i)来控制其输入。γ(i)[j]表示来自第j个ST块bj的输入应该如何被当前ST块bi使用。例如,γ (4)[1]=0.6表示输入中来自b1的输出应占60%。由于我们限制bi只受编号小于i的ST块的影响,因此对于j≥i,γ(i)[j]=0。因此,γ(i)是一个长度为i的向量。

在输出方面,我们采用连结机制。也就是说,ST块bi的输出向量将与其他ST块的输出向量连结,以作为ST-backbone的最终输出。

图5显示了四个示例ST-backbone。我们可以看到γ可以确定不同ST块之间的灵活拓扑结构。例如,图5(a)对应于传统的堆叠ST块结构,因为每个ST块bi只接受上一个 ST块bi-1的输出。图5(b)展示了一种非常灵活的结构,其中b4接收来自所有前面ST块的输出。图5(c)展示了一种中等复杂的结构,其中b4接收来自b1和b3的输出。图5(d)展示了一种不常见的结构,其中b4只接收来自b2的输出。

3.3.2 宏搜索空间。给定最大ST块数量NB,宏搜索空间由所有可能的ST-backbone拓扑结构组成。将ST块视为原子单元,宏搜索空间的大小等于所有可能的有向无环图的数量,约为O(N!NN2)。例如,当NB=4时,宏搜索空间的大小为21,406。通过在实践中限制NB为一个较小的值(我们使用NB=4),宏搜索空间仍然可以被有效探索。

宏搜索空间限制了每个ST块输入连接的数量,以减少内存和计算成本。例如,在图5(b)中,b4接收来自所有先前ST块的输出,这可能会很昂贵。相反,我们限制每个ST块最多只能从α个先前的ST块接收输入,其中α是一个可配置的超参数。在我们的实验中,我们将α设置为2。

3.4 搜索策略
我们提出了一种联合搜索策略,能够同时探索微搜索空间和宏搜索空间,以发现高性能的预测模型。

3.4.1 问题形式化。我们将联合搜索问题形式化为多目标优化问题。具体来说,给定时间序列数据X和相应的时空图G,我们的目标是找到最优架构α*、β*和γ*,使得:

α*,β*,γ* = arg min
α,β,γ

L(fα,β,γ(X,G))

其中L是损失函数(如均方根误差),用于衡量模型fα,β,γ在数据X和G上的性能。fα,β,γ是我们的预测模型,其中α参数化ST块的内部结构,β参数化ST块中不同表示之间的连接,γ参数化ST-backbone中不同ST块之间的连接。

这是一个具有挑战性的多目标优化问题,因为三组参数α、β和γ是相互依赖的。也就是说,在搜索γ以确定最优ST-backbone时,我们需要先确定每个ST块的架构(α和β)。同样,在搜索ST块架构(α和β)时,我们需要了解其将如何连接到ST-backbone(γ)。为了有效解决这一挑战,我们将搜索过程分成两个阶段:

1. 首先,我们固定γ,并对α和β的组合进行搜索,以发现有前景的异构ST块集合。
2. 其次,利用从第一阶段发现的异构ST块集合,我们对γ进行搜索,以确定灵活ST-backbone的最佳连接拓扑。

3.4.2 发现ST块。在第一阶段,我们搜索有前景的异构ST块,并确定它们的内部结构(α和β)。具体来说,对于每个候选ST块架构{α,β},我们使用一种简单的ST-backbone结构,即将该ST块与自身连接NB-1次,如图6所示。注意,此时ST-backbone的连接方式(γ)是固定的。

然后,我们在数据集上训练该ST-backbone模型,并评估其性能,产生验证损失L{α, β}。我们对微搜索空间中的所有可能{α,β}组合执行上述过程,并选择K个得分最高的ST块,即L{α,β}最小的K个。

这种基于搜索和评分的ST块发现策略允许我们识别出对于特定数据集最合适的ST块。不同于现有方法使用人工设计的ST块,我们的方法可以自动识别出能最大限度捕获时态依赖性和空间相关性的ST块。

3.4.3 搜索ST-backbone。一旦我们发现了K个有前景的异构ST块,就可以在宏搜索空间中搜索最优ST-backbone架构。特别是对于每个ST-backbone候选架构γ,我们用从第一阶段发现的K个ST块来实例化该架构。然后,我们训练和评估该ST-backbone模型的性能,得到验证损失L(γ)。我们对宏搜索空间中的所有候选架构执行上述过程,并选择导致最小验证损失L(γ)的架构γ*作为我们的最优ST-backbone架构。

这样的自动化搜索策略允许我们探索大量ST-backbones,超越了现有工作中使用同质ST块和简单堆叠拓扑的局限性。通过联合微搜索和宏搜索,我们可以同时优化ST块和ST-backbone架构,以提高最终的预测性能。

4 实验
在本节中,我们将评估AutoCTS的有效性和优势。我们首先介绍实验设置,包括数据集、基线模型、评估指标和实现细节。然后,我们报告了AutoCTS和其他最先进方法在8个公开基准数据集上的实验结果。此外,我们进行了一些研究来深入理解和分析AutoCTS的行为。最后,我们讨论了一些具有挑战性的情况,在这些情况下AutoCTS可能会受到限制。

4.1 实验设置
数据集。我们在8个公开基准数据集上评估AutoCTS,包括4个交通数据集(METR-LA、PEMS-BAY、PEMS08和PEMS03)、2个气象数据集(WIND和RASM)以及2个其他类型的数据集(ECG和ETTh1)。这些数据集广泛用于评估相关时间序列预测模型。

基线模型。我们将AutoCTS与8种最先进的人工设计基线模型进行比较:STGCN [51]、DCRNN [16]、Graph WaveNet [46]、MTGNN [53]、AGCRN [47]、 STSGCN[11]、PEMSSTGCN [9]和PMGR [29]。这些模型代表了最新的相关时间序列预测研究成果。

评估指标。我们使用平均绝对百分比误差(MAPE)、平均绝对误差(MAE)和均方根误差(RMSE)作为评估指标。这些指标广泛用于评估时间序列预测模型。

实现细节。我们采用NVIDIA GeForce RTX 3090 GPU来加速训练和评估过程。对于微搜索空间,我们将ST块中最大潜在表示数M设置为6。对于宏搜索空间,我们将最大ST块数NB设置为4,每个ST块最多接收2个先验ST块的输入。我们在微搜索阶段选择了10个最佳ST块(K=10),并将它们用于宏搜索阶段。

4.2 整体性能比较
表2展示了AutoCTS和8个基线模型在所有8个数据集上的整体性能。从结果可以看出,AutoCTS显著优于所有基线模型,在所有指标上都达到了最佳性能。具体来说,AutoCTS在MAPE、MAE和RMSE上比最佳基线模型分别提高了18.3%、15.8%和14.0%。这一发现凸显了自动设计ST块和ST-backbone架构的重要性和效用。

4.3 数据集级别性能
除了整体性能外,我们还分析了AutoCTS和基线模型在每个数据集上的具体表现,结果如表3所示。我们可以观察到以下几点:

(1) AutoCTS在所有8个数据集上都达到了最佳性能,而其他人工设计模型在不同数据集上的表现参差不齐。这证实了AutoCTS具有出色的普遍性和一致性。

(2) PMGR在一些数据集上表现良好,但在RASM和ETTh1数据集上表现很差。相比之下,AutoCTS在所有数据集上都展现了稳定的性能。

(3) 一些针对特定领域(如交通)设计的基线模型,如PEMS-STGCN,在相关领域数据集(METR-LA、PEMS-BAY、PEMS08和PEMS03)上表现较好,但在其他领域数据集上表现不佳。这再次说明了人工设计模型可能存在有限泛化能力的问题。

(4) AutoCTS在某些数据集上的性能优势相对更加显著,如RASM (48.7%的MAPE改进)、ECG (27.4%)和ETTh1(22.3%)。这些数据集可能具有一些独特的特征,很难被人工设计模型捕捉到,但可以被AutoCTS自动发现和利用。

总的来说,上述发现强化了我们设计AutoCTS的核心动机:自动化架构搜索可以克服人工设计模型的局限性,为不同领域发现高度优化和泛化的模型,从而获得一致的预测改进。

4.4 不同组件的影响
为了深入理解AutoCTS中不同组件的影响,我们进行了一系列控制实验,结果如表4所示。

首先,我们评估了仅使用微搜索的有效性(AutoCTS w/ 仅微搜索)。具体来说,我们只对ST块架构(α和β)进行搜索,同时使用了与基线模型STGCN相同的堆叠ST块架构。从结果可以看出,即使在这种受限情况下,AutoCTS仍能显著优于大多数基线模型。这证明了AutoCTS在设计高效ST块方面的能力。其次,我们评估了仅使用宏搜索的有效性(AutoCTS w/ 仅宏搜索)。在这种情况下,我们使用人工设计的ST块(如STGCN中的ST块),但对ST-backbone的拓扑结构(γ)进行搜索。结果显示,这种设置也能带来一定的性能提升,但提升幅度有限。这凸显了微搜索(ST块设计)对整体性能的重要性。

最后,当同时使用微搜索和宏搜索时(完整AutoCTS),我们获得了最佳性能。这验证了联合优化ST块和ST-backbone架构的必要性。

4.5 AutoCTS行为分析
为了更深入地理解AutoCTS发现的ST块和ST-backbone架构,我们进行了一些行为分析。

4.5.1 可视化ST块。图7(a)显示了由AutoCTS自动设计的一个ST块示例,其中包含6个潜在表示(h0到h5)。我们可以观察到以下几个有趣的现象:

(1) 该ST块由多种不同的算子组成,如注意力(Attention)、卷积(Conv)和密集层(DenseLayer)等。这种异构架构使ST块能够同时捕获复杂的时空模式。

(2) h4表示通过应用GraphConv在节点特征上累计来自不同时间步的信息,因此它很可能捕获了时态依赖性。

(3) h5表示通过应用注意力机制在节点上累计来自不同空间位置的信息,因此它很可能捕获了空间相关性。

(4) 最终输出是通过组合h4和h5得到的,结合了时间和空间两个维度的特征。

这种行为分析为我们提供了有价值的见解,说明了AutoCTS如何设计出高效的异构ST块,以同时捕获时间和空间模式。

4.5.2 可视化ST-Backbone。图7(b)显示了一个由AutoCTS发现的ST-backbone架构示例。我们可以观察到以下有趣的现象:

(1) 这种混合拓扑结构中包含多种不同的ST块之间的连接,而不仅仅是简单的堆叠。例如,b4接收来自b1和b3的输入。

(2) 每个ST块从不同的先验ST块接收输入比例不同。例如,b4主要依赖b1的输入(γ(4)[1]=0.8)。

(3) 不同的ST块被设计用于捕获不同类型的模式。例如,b3似乎捕获了一些独特的时空模式,因为它将其特征直接传递给了b4。

这种行为分析说明了AutoCTS如何通过搜索发现灵活和高效的ST-backbone架构,从而充分利用异构ST块之间的协同作用。

4.6 AutoCTS的局限性
虽然AutoCTS在我们的广泛实验中表现出了优异性能,但它仍然存在一些局限性和潜在的改进空间。

(1) 尽管我们设计了微搜索和宏搜索空间来控制搜索成本,但联合搜索过程仍然相对昂贵。进一步减小搜索空间、加速模型评估或开发更有效的搜索算法等方面都有提升的空间。

(2) 我们的搜索策略目前主要侧重于优化短期预测性能,但对长期预测行为没有明确的考虑。将长期一致性显式纳入优化目标可能会带来额外的收益。

(3) 我们假设所有时间序列共享相同的ST块和ST-backbone架构。然而,在某些情况下,不同时间序列可能需要定制的架构才能充分利用其独特模式。支持针对每个时间序列或时间序列群的个性化架构搜索可能会提高性能。

(4) 我们目前的实现只考虑了静态图信号,而没有处理时变图序列。为了支持更广泛的应用场景,未来的工作可以扩展以支持动态图输入。

(5) 当前版本的AutoCTS仅用于单步预测。对多步、多变量和概率预测等更复杂预测任务的支持有待进一步研究。

总之,尽管AutoCTS展现了自动化架构搜索在相关时间序列预测领域的巨大潜力,但仍有很大的改进空间,值得进一步探索和研究。